{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mEF7O2dMog9R"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = '****'\n",
        "os.environ['LANGCHAIN_API_KEY'] = '****'\n",
        "os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
        "os.environ['LANGCHAIN_ENDPOINT'] = 'https://api.smith.langchain.com'\n",
        "os.environ['LANGCHAIN_PROJECT'] = '08-05'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain-upstage 0.4.0 requires tokenizers<0.20.0,>=0.19.1, but you have tokenizers 0.21.0 which is incompatible.\n"
          ]
        }
      ],
      "source": [
        "!pip install -qU langchain_community"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "texts = [\n",
        "    \"안녕, 만나서 반가워.\",\n",
        "    \"LangChain simplifies the process of building applications with large language models\",\n",
        "    \"랭체인 한국어 튜토리얼은 LangChain의 공식 문서, cookbook 및 다양한 실용 예제를 바탕으로 하여 사용자가 LangChain을 더 쉽고 효과적으로 활용할 수 있도록 구성되어 있습니다. \",\n",
        "    \"LangChain은 초거대 언어모델로 애플리케이션을 구축하는 과정을 단순화합니다.\",\n",
        "    \"Retrieval-Augmented Generation (RAG) is an effective technique for improving AI responses.\",\n",
        "]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 지원되는 임베딩 모델 확인\n",
        "\n",
        "- https://ollama.com/library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_community.embeddings import OllamaEmbeddings\n",
        "\n",
        "ollama_embeddings = OllamaEmbeddings(\n",
        "    model=\"nomic-embed-text\",\n",
        "    # model=\"chatfire/bge-m3:q8_0\" # BGE-M3\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "768"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 쿼리 임베딩\n",
        "embedded_query = ollama_embeddings.embed_query(\"LangChain 에 대해서 상세히 알려주세요.\")\n",
        "# 임베딩 차원 출력\n",
        "len(embedded_query)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 문서 임베딩\n",
        "embedded_documents = ollama_embeddings.embed_documents(texts)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[-0.24748356640338898,\n",
              " -0.23559220135211945,\n",
              " -2.8910884857177734,\n",
              " -0.6004036664962769,\n",
              " 0.6054303050041199]"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "embedded_documents[0][:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import numpy as np\n",
        "\n",
        "# # 질문(embedded_query): LangChain 에 대해서 알려주세요.\n",
        "# similarity = np.array(embedded_query) @ np.array(embedded_documents).T\n",
        "\n",
        "# # 유사도 기준 내림차순 정렬\n",
        "# sorted_idx = (np.array(embedded_query) @ np.array(embedded_documents).T).argsort()[::-1]\n",
        "\n",
        "# # 결과 출력\n",
        "# print(\"[Query] LangChain 에 대해서 알려주세요.\\n====================================\")\n",
        "# for i, idx in enumerate(sorted_idx):\n",
        "#     print(f\"[{i}] 유사도: {similarity[idx]:.3f} | {texts[idx]}\")\n",
        "#     print()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Query] LangChain 에 대해서 알려주세요.\n",
            "====================================\n",
            "[0] 유사도: 1.000 | LangChain은 초거대 언어모델로 애플리케이션을 구축하는 과정을 단순화합니다.\n",
            "\n",
            "[1] 유사도: 0.753 | 랭체인 한국어 튜토리얼은 LangChain의 공식 문서, cookbook 및 다양한 실용 예제를 바탕으로 하여 사용자가 LangChain을 더 쉽고 효과적으로 활용할 수 있도록 구성되어 있습니다. \n",
            "\n",
            "[2] 유사도: 0.558 | LangChain simplifies the process of building applications with large language models\n",
            "\n",
            "[3] 유사도: 0.550 | 안녕, 만나서 반가워.\n",
            "\n",
            "[4] 유사도: 0.000 | Retrieval-Augmented Generation (RAG) is an effective technique for improving AI responses.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# 질문(embedded_query): LangChain 에 대해서 알려주세요.\n",
        "similarity = np.array(embedded_query) @ np.array(embedded_documents).T\n",
        "\n",
        "# 유사도 기준 내림차순 정렬\n",
        "sorted_idx = similarity.argsort()[::-1]\n",
        "\n",
        "# 유사도 정규화 (최소값 0, 최대값 1로 변환)\n",
        "similarity_min = similarity.min()\n",
        "similarity_max = similarity.max()\n",
        "normalized_similarity = (similarity - similarity_min) / (similarity_max - similarity_min)\n",
        "\n",
        "# 결과 출력\n",
        "print(\"[Query] LangChain 에 대해서 알려주세요.\\n====================================\")\n",
        "for i, idx in enumerate(sorted_idx):\n",
        "    print(f\"[{i}] 유사도: {normalized_similarity[idx]:.3f} | {texts[idx]}\")\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python (app)",
      "language": "python",
      "name": "app"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
